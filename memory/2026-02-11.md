# 2026-02-11 — Initial Build + Fetch Delay & Count

## Summary
Built the Twitter/X Bookmarks Backup CLI tool from scratch. A Python CLI that fetches bookmarks from Twitter's internal GraphQL API and exports them to a single `bookmarks.md` file.

## Key Decisions
- **Direct API calls** via `httpx` instead of `bird` CLI (avoids Node.js dependency)
- **Cookie-based auth** using `auth_token` + `ct0` from browser DevTools
- **Single markdown output** file grouped by date, newest first
- **State tracking** via `.state/processed_ids.json` for incremental fetches

## Files Created
- `src/twitter_bookmarks/` — 8 modules (cli, config, client, parser, models, markdown, state, logging_config)
- `tests/` — 5 test files with 42 passing tests
- `pyproject.toml` — deps: httpx, click, tomli-w
- `README.md`, `ARCHITECTURE.md`, `CLAUDE.md`, `PROMPT.md`

## Fetch Delay & Count Feature (Session 2)
Added configurable delay between API requests and `--count` flag:
- `config.py`: Added `fetch_delay: float = 2.0` to `AppConfig`, `[fetch]` TOML section
- `client.py`: Added `delay` and `max_count` params to `fetch_all_bookmarks()`
- `cli.py`: Added `--count`/`-n` and `--delay` CLI options to `fetch` command
- Config hierarchy: CLI flag > config file > default (2.0s)
- 4 new tests (delay mock, max_count stop, max_count truncate, CLI help flags)

## Query ID & 404 Handling (Session 3)
Added configurable query ID and 404 error handling for stale GraphQL IDs:
- `client.py`: 404 response now raises descriptive error with instructions to update query ID. `TwitterClient` accepts `query_id` param (per-instance URL instead of module constant).
- `config.py`: Added `query_id: str | None` to `AppConfig`, stored under `[api]` section in TOML.
- `cli.py`: Added `--query-id-only` flag to `setup` for quick query ID updates without re-entering auth tokens. Full `setup` now prompts for optional query ID.
- `cli.py` (`fetch`): Passes `config.query_id` to `TwitterClient`.
- 2 new tests: `test_stale_query_id_raises`, `test_custom_query_id`
- Updated `ARCHITECTURE.md` and `README.md` with query ID docs and 404 troubleshooting.

## Resilient User Extraction & --dump-raw (Session 4)
Fixed "Unknown" author usernames — all bookmarks showed `@unknown` because the parser had a single hardcoded key path for user data that didn't match the live API response structure.

### Changes
- **`parser.py`**: Extracted `_extract_user()` helper with multi-path fallback:
  1. `core.user_results.result.legacy` (standard)
  2. `core.user_result.result.legacy` (singular variant)
  3. `core.user_results.result` directly (flattened, no `legacy` wrapper)
  4. `_deep_find_user()` recursive search (last resort, max 6 levels)
  - Added `logger.debug()` calls showing actual keys at each nesting level
  - Added `logger.warning()` when username falls back to "unknown"
  - Quoted tweet user extraction also uses `_extract_user()` now
- **`client.py`**: Added `capture_raw` param + `raw_responses` list to capture raw API JSON
- **`cli.py`**: Added `--dump-raw <path>` option to `fetch` command — saves raw API responses + entries to JSON for debugging
- **Tests**: 11 new tests (7 for `_extract_user`, 4 for `_deep_find_user`, 1 CLI test for `--dump-raw`)
- **Fixture**: Added `bookmarks_response_singular_user.json`

## Status
- 55/56 tests passing (1 pre-existing failure: `test_status_with_config` — logging to closed file)
- CLI working (`setup`, `fetch`, `status` commands)
- User extraction is now resilient to Twitter API key path changes
